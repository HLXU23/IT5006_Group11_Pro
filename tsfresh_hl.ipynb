{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hlxu\\.conda\\envs\\IT5006\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch import optim as optim\n",
    "from cmapss import cmapss\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sets = ['FD001', 'FD002', 'FD003', 'FD004']\n",
    "model_name = 'Hybrid'\n",
    "feature_extract_mode = 'default'\n",
    "# feature_extract_mode = 'tsfresh'\n",
    "\n",
    "iteration_num = 10\n",
    "window_size = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20631, 17)\n",
      "(13096, 17)\n",
      "dataset load successfully!\n"
     ]
    }
   ],
   "source": [
    "set_name = 'FD001'\n",
    "trainset = cmapss(mode='train',\n",
    "                feature_extract_mode=feature_extract_mode,\n",
    "                dataset=f'./CMAPSSData/train_{set_name}_processed.csv',\n",
    "                window_size=window_size)\n",
    "testset = cmapss(mode='test',\n",
    "            feature_extract_mode=feature_extract_mode,\n",
    "            dataset=f'./CMAPSSData/test_{set_name}_processed.csv',\n",
    "            rul_result=f'./CMAPSSData/RUL_{set_name}.txt',\n",
    "            window_size=window_size)\n",
    "\n",
    "print('dataset load successfully!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainset.feature_extract()\n",
    "# testset.feature_extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "num_samples should be a positive integer value, but got num_samples=0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m \u001b[43mDataLoader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrainset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrainset\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m test_loader \u001b[38;5;241m=\u001b[39m DataLoader(dataset\u001b[38;5;241m=\u001b[39mtestset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(testset), shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\hlxu\\.conda\\envs\\IT5006\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:277\u001b[0m, in \u001b[0;36mDataLoader.__init__\u001b[1;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# map-style\u001b[39;00m\n\u001b[0;32m    276\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m shuffle:\n\u001b[1;32m--> 277\u001b[0m         sampler \u001b[38;5;241m=\u001b[39m \u001b[43mRandomSampler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgenerator\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    278\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    279\u001b[0m         sampler \u001b[38;5;241m=\u001b[39m SequentialSampler(dataset)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\hlxu\\.conda\\envs\\IT5006\\lib\\site-packages\\torch\\utils\\data\\sampler.py:97\u001b[0m, in \u001b[0;36mRandomSampler.__init__\u001b[1;34m(self, data_source, replacement, num_samples, generator)\u001b[0m\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreplacement should be a boolean value, but got \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     94\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreplacement=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplacement))\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m---> 97\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_samples should be a positive integer \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     98\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue, but got num_samples=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples))\n",
      "\u001b[1;31mValueError\u001b[0m: num_samples should be a positive integer value, but got num_samples=0"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(dataset=trainset, batch_size=len(trainset), shuffle=True, num_workers=2)\n",
    "test_loader = DataLoader(dataset=testset, batch_size=len(testset), shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Index: 0\n",
      "Inputs Shape: torch.Size([17731, 30, 17])\n",
      "Labels Shape: torch.Size([17731, 1])\n"
     ]
    }
   ],
   "source": [
    "for batch_index, data in enumerate(train_loader, 0):\n",
    "    inputs, handcrafted_feature, labels = data\n",
    "\n",
    "    print(f\"Batch Index: {batch_index}\")\n",
    "    print(f\"Inputs Shape: {inputs.shape}\")\n",
    "    # print(f\"Handcrafted Features Shape: {handcrafted_feature.shape}\")\n",
    "    print(f\"Labels Shape: {labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsfresh import extract_relevant_features\n",
    "from tsfresh.utilities.dataframe_functions import impute\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_and_select_tsfresh_features(inputs, labels, column_id=\"id\", column_sort=\"time\", column_value=\"value\"):\n",
    "    if isinstance(inputs, torch.Tensor):\n",
    "        inputs = inputs.numpy()\n",
    "    if isinstance(labels, torch.Tensor):\n",
    "        labels = labels.numpy()\n",
    "    \n",
    "    time_series_df = pd.DataFrame()\n",
    "\n",
    "    for unit_idx in tqdm(range(inputs.shape[0]), desc=\"Initialization\", unit=\"sample\"):\n",
    "        for feature_dim in range(inputs.shape[2]):\n",
    "            ts_data = pd.DataFrame({\n",
    "                column_id: unit_idx,\n",
    "                column_sort: range(inputs.shape[1]),\n",
    "                column_value: inputs[unit_idx, :, feature_dim]\n",
    "            })\n",
    "            ts_data['feature_dim'] = feature_dim\n",
    "            time_series_df = pd.concat([time_series_df, ts_data], ignore_index=True)\n",
    "\n",
    "    relevant_features = extract_relevant_features(time_series_df, \n",
    "                                                  y=pd.Series(labels.flatten()), \n",
    "                                                  column_id=column_id, \n",
    "                                                  column_sort=column_sort, \n",
    "                                                  column_kind='feature_dim', \n",
    "                                                  column_value=column_value)\n",
    "    \n",
    "    impute(relevant_features)\n",
    "    return relevant_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialization: 100%|██████████| 100/100 [00:00<00:00, 137.53sample/s]\n",
      "Feature Extraction: 100%|██████████| 40/40 [00:23<00:00,  1.67it/s]\n"
     ]
    }
   ],
   "source": [
    "extracted_features = extract_and_select_tsfresh_features(inputs[:100], labels[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(extracted_features.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=20)  # Retain 95% of the variance\n",
    "reduced_features = pca.fit_transform(extracted_features)\n",
    "selected_features_pca = pd.DataFrame(reduced_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.538601</td>\n",
       "      <td>99.788538</td>\n",
       "      <td>-73.616616</td>\n",
       "      <td>-119.998600</td>\n",
       "      <td>7.415103</td>\n",
       "      <td>24.038515</td>\n",
       "      <td>50.551229</td>\n",
       "      <td>8.455851</td>\n",
       "      <td>-0.790781</td>\n",
       "      <td>-2.539496</td>\n",
       "      <td>4.063649</td>\n",
       "      <td>-5.180844</td>\n",
       "      <td>1.795415</td>\n",
       "      <td>3.491117</td>\n",
       "      <td>-1.977848</td>\n",
       "      <td>-1.786578</td>\n",
       "      <td>-1.040339</td>\n",
       "      <td>-2.298895</td>\n",
       "      <td>2.551714</td>\n",
       "      <td>-1.453487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-71.885615</td>\n",
       "      <td>-65.216774</td>\n",
       "      <td>-24.882602</td>\n",
       "      <td>71.485807</td>\n",
       "      <td>11.338036</td>\n",
       "      <td>40.986940</td>\n",
       "      <td>49.297086</td>\n",
       "      <td>8.641171</td>\n",
       "      <td>4.214721</td>\n",
       "      <td>-3.046241</td>\n",
       "      <td>0.545859</td>\n",
       "      <td>-6.259857</td>\n",
       "      <td>-0.088238</td>\n",
       "      <td>-2.395807</td>\n",
       "      <td>2.184409</td>\n",
       "      <td>-2.750752</td>\n",
       "      <td>-4.565312</td>\n",
       "      <td>0.807413</td>\n",
       "      <td>-3.259262</td>\n",
       "      <td>2.863426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>51.063344</td>\n",
       "      <td>-82.136767</td>\n",
       "      <td>-119.916713</td>\n",
       "      <td>-1.531582</td>\n",
       "      <td>-8.413727</td>\n",
       "      <td>-53.257087</td>\n",
       "      <td>-165.592956</td>\n",
       "      <td>5.841684</td>\n",
       "      <td>1.897689</td>\n",
       "      <td>-1.942060</td>\n",
       "      <td>-3.084503</td>\n",
       "      <td>-1.294967</td>\n",
       "      <td>-0.265935</td>\n",
       "      <td>0.345316</td>\n",
       "      <td>-2.764307</td>\n",
       "      <td>-0.606400</td>\n",
       "      <td>1.261577</td>\n",
       "      <td>-0.012268</td>\n",
       "      <td>-1.780252</td>\n",
       "      <td>0.148068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-26.795507</td>\n",
       "      <td>-104.203966</td>\n",
       "      <td>-9.189505</td>\n",
       "      <td>110.344172</td>\n",
       "      <td>110.575284</td>\n",
       "      <td>27.534322</td>\n",
       "      <td>-84.109203</td>\n",
       "      <td>16.391240</td>\n",
       "      <td>-4.494083</td>\n",
       "      <td>10.342198</td>\n",
       "      <td>-0.985391</td>\n",
       "      <td>2.905408</td>\n",
       "      <td>0.094030</td>\n",
       "      <td>0.270660</td>\n",
       "      <td>-0.928903</td>\n",
       "      <td>0.182100</td>\n",
       "      <td>1.889517</td>\n",
       "      <td>2.438300</td>\n",
       "      <td>-1.323451</td>\n",
       "      <td>-0.109358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>98.543128</td>\n",
       "      <td>-7.930621</td>\n",
       "      <td>-90.018536</td>\n",
       "      <td>-81.017968</td>\n",
       "      <td>-63.297021</td>\n",
       "      <td>-123.270113</td>\n",
       "      <td>-167.343144</td>\n",
       "      <td>18.606344</td>\n",
       "      <td>0.235378</td>\n",
       "      <td>2.281100</td>\n",
       "      <td>0.680885</td>\n",
       "      <td>-0.429602</td>\n",
       "      <td>3.211319</td>\n",
       "      <td>2.000023</td>\n",
       "      <td>4.441433</td>\n",
       "      <td>0.479843</td>\n",
       "      <td>-0.586156</td>\n",
       "      <td>-0.148288</td>\n",
       "      <td>4.179987</td>\n",
       "      <td>0.823956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>-114.315709</td>\n",
       "      <td>-179.141293</td>\n",
       "      <td>-75.876045</td>\n",
       "      <td>45.379685</td>\n",
       "      <td>-55.636952</td>\n",
       "      <td>23.665242</td>\n",
       "      <td>-27.415572</td>\n",
       "      <td>0.952180</td>\n",
       "      <td>-2.073161</td>\n",
       "      <td>-6.721170</td>\n",
       "      <td>-1.134203</td>\n",
       "      <td>-0.495388</td>\n",
       "      <td>1.135689</td>\n",
       "      <td>1.402442</td>\n",
       "      <td>-1.179734</td>\n",
       "      <td>2.376745</td>\n",
       "      <td>-3.922307</td>\n",
       "      <td>0.172131</td>\n",
       "      <td>3.941521</td>\n",
       "      <td>1.577354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>-107.811158</td>\n",
       "      <td>-148.861083</td>\n",
       "      <td>-4.779699</td>\n",
       "      <td>50.691432</td>\n",
       "      <td>119.882942</td>\n",
       "      <td>-6.739749</td>\n",
       "      <td>47.982642</td>\n",
       "      <td>-6.661037</td>\n",
       "      <td>-8.534820</td>\n",
       "      <td>1.427000</td>\n",
       "      <td>-4.487593</td>\n",
       "      <td>1.977316</td>\n",
       "      <td>2.630347</td>\n",
       "      <td>5.517431</td>\n",
       "      <td>-3.852986</td>\n",
       "      <td>-0.569040</td>\n",
       "      <td>1.469857</td>\n",
       "      <td>0.974105</td>\n",
       "      <td>-1.655281</td>\n",
       "      <td>-0.864231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>-202.506591</td>\n",
       "      <td>57.521400</td>\n",
       "      <td>-60.670800</td>\n",
       "      <td>-27.653339</td>\n",
       "      <td>-58.252775</td>\n",
       "      <td>49.856865</td>\n",
       "      <td>1.768259</td>\n",
       "      <td>15.855072</td>\n",
       "      <td>-5.978626</td>\n",
       "      <td>-1.231114</td>\n",
       "      <td>8.896695</td>\n",
       "      <td>3.416395</td>\n",
       "      <td>-3.592319</td>\n",
       "      <td>1.729327</td>\n",
       "      <td>-3.821998</td>\n",
       "      <td>4.352909</td>\n",
       "      <td>-4.839882</td>\n",
       "      <td>2.713912</td>\n",
       "      <td>0.352079</td>\n",
       "      <td>2.605625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>-91.710065</td>\n",
       "      <td>-148.780652</td>\n",
       "      <td>31.525771</td>\n",
       "      <td>3.410131</td>\n",
       "      <td>-90.888194</td>\n",
       "      <td>13.072785</td>\n",
       "      <td>-50.229040</td>\n",
       "      <td>-21.725943</td>\n",
       "      <td>-10.576832</td>\n",
       "      <td>-3.985462</td>\n",
       "      <td>-1.231781</td>\n",
       "      <td>-1.414247</td>\n",
       "      <td>2.868721</td>\n",
       "      <td>5.562184</td>\n",
       "      <td>1.252884</td>\n",
       "      <td>-7.759863</td>\n",
       "      <td>-0.768211</td>\n",
       "      <td>-0.479793</td>\n",
       "      <td>2.922469</td>\n",
       "      <td>0.820814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>11.488731</td>\n",
       "      <td>56.137958</td>\n",
       "      <td>-69.736862</td>\n",
       "      <td>100.369875</td>\n",
       "      <td>-99.317755</td>\n",
       "      <td>-110.550424</td>\n",
       "      <td>-209.412599</td>\n",
       "      <td>18.540452</td>\n",
       "      <td>4.521250</td>\n",
       "      <td>-5.405268</td>\n",
       "      <td>-1.193100</td>\n",
       "      <td>-0.103573</td>\n",
       "      <td>-4.880953</td>\n",
       "      <td>-4.476846</td>\n",
       "      <td>4.781715</td>\n",
       "      <td>1.689466</td>\n",
       "      <td>1.013122</td>\n",
       "      <td>1.211548</td>\n",
       "      <td>-2.789086</td>\n",
       "      <td>-1.784157</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0           1           2           3           4           5   \\\n",
       "0    11.538601   99.788538  -73.616616 -119.998600    7.415103   24.038515   \n",
       "1   -71.885615  -65.216774  -24.882602   71.485807   11.338036   40.986940   \n",
       "2    51.063344  -82.136767 -119.916713   -1.531582   -8.413727  -53.257087   \n",
       "3   -26.795507 -104.203966   -9.189505  110.344172  110.575284   27.534322   \n",
       "4    98.543128   -7.930621  -90.018536  -81.017968  -63.297021 -123.270113   \n",
       "..         ...         ...         ...         ...         ...         ...   \n",
       "95 -114.315709 -179.141293  -75.876045   45.379685  -55.636952   23.665242   \n",
       "96 -107.811158 -148.861083   -4.779699   50.691432  119.882942   -6.739749   \n",
       "97 -202.506591   57.521400  -60.670800  -27.653339  -58.252775   49.856865   \n",
       "98  -91.710065 -148.780652   31.525771    3.410131  -90.888194   13.072785   \n",
       "99   11.488731   56.137958  -69.736862  100.369875  -99.317755 -110.550424   \n",
       "\n",
       "            6          7          8          9         10        11        12  \\\n",
       "0    50.551229   8.455851  -0.790781  -2.539496  4.063649 -5.180844  1.795415   \n",
       "1    49.297086   8.641171   4.214721  -3.046241  0.545859 -6.259857 -0.088238   \n",
       "2  -165.592956   5.841684   1.897689  -1.942060 -3.084503 -1.294967 -0.265935   \n",
       "3   -84.109203  16.391240  -4.494083  10.342198 -0.985391  2.905408  0.094030   \n",
       "4  -167.343144  18.606344   0.235378   2.281100  0.680885 -0.429602  3.211319   \n",
       "..         ...        ...        ...        ...       ...       ...       ...   \n",
       "95  -27.415572   0.952180  -2.073161  -6.721170 -1.134203 -0.495388  1.135689   \n",
       "96   47.982642  -6.661037  -8.534820   1.427000 -4.487593  1.977316  2.630347   \n",
       "97    1.768259  15.855072  -5.978626  -1.231114  8.896695  3.416395 -3.592319   \n",
       "98  -50.229040 -21.725943 -10.576832  -3.985462 -1.231781 -1.414247  2.868721   \n",
       "99 -209.412599  18.540452   4.521250  -5.405268 -1.193100 -0.103573 -4.880953   \n",
       "\n",
       "          13        14        15        16        17        18        19  \n",
       "0   3.491117 -1.977848 -1.786578 -1.040339 -2.298895  2.551714 -1.453487  \n",
       "1  -2.395807  2.184409 -2.750752 -4.565312  0.807413 -3.259262  2.863426  \n",
       "2   0.345316 -2.764307 -0.606400  1.261577 -0.012268 -1.780252  0.148068  \n",
       "3   0.270660 -0.928903  0.182100  1.889517  2.438300 -1.323451 -0.109358  \n",
       "4   2.000023  4.441433  0.479843 -0.586156 -0.148288  4.179987  0.823956  \n",
       "..       ...       ...       ...       ...       ...       ...       ...  \n",
       "95  1.402442 -1.179734  2.376745 -3.922307  0.172131  3.941521  1.577354  \n",
       "96  5.517431 -3.852986 -0.569040  1.469857  0.974105 -1.655281 -0.864231  \n",
       "97  1.729327 -3.821998  4.352909 -4.839882  2.713912  0.352079  2.605625  \n",
       "98  5.562184  1.252884 -7.759863 -0.768211 -0.479793  2.922469  0.820814  \n",
       "99 -4.476846  4.781715  1.689466  1.013122  1.211548 -2.789086 -1.784157  \n",
       "\n",
       "[100 rows x 20 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_features_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hlxu\\.conda\\envs\\IT5006\\lib\\site-packages\\sklearn\\base.py:1473: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "model = RandomForestRegressor()\n",
    "model.fit(extracted_features, labels[:100])  # y can be constant\n",
    "feature_importances = model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>15</th>\n",
       "      <th>25</th>\n",
       "      <th>31</th>\n",
       "      <th>58</th>\n",
       "      <th>79</th>\n",
       "      <th>91</th>\n",
       "      <th>95</th>\n",
       "      <th>150</th>\n",
       "      <th>158</th>\n",
       "      <th>633</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.038072</td>\n",
       "      <td>0.232923</td>\n",
       "      <td>0.044069</td>\n",
       "      <td>0.019219</td>\n",
       "      <td>0.02169</td>\n",
       "      <td>0.073187</td>\n",
       "      <td>0.010491</td>\n",
       "      <td>0.022166</td>\n",
       "      <td>0.021668</td>\n",
       "      <td>0.022293</td>\n",
       "      <td>0.086632</td>\n",
       "      <td>0.012217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         15        25       31        58        79   \\\n",
       "0  0.038072  0.232923  0.044069  0.019219  0.02169  0.073187  0.010491   \n",
       "\n",
       "        91        95        150       158       633  \n",
       "0  0.022166  0.021668  0.022293  0.086632  0.012217  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importance = pd.DataFrame(feature_importances).T\n",
    "filtered_importance = importance.loc[:, (importance > 0.01).iloc[0]]\n",
    "filtered_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([0, 1, 15, 25, 31, 58, 79, 91, 95, 150, 158, 633], dtype='int64')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_indices = filtered_importance.columns\n",
    "col_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_train = extracted_features.iloc[:, col_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "corr_matrix = filtered_train.corr()\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')\n",
    "plt.title(\"Feature Correlation Matrix\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IT5006",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
